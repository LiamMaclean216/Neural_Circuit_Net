{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_size = 25\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.ToTensor()),\n",
    "        batch_size = batch_size, shuffle=True)\n",
    "\n",
    "from random import randint\n",
    "\n",
    "print(\"kk\")\n",
    "\n",
    "\n",
    "##### TODO ######\n",
    "# Circuit picking (all the reshapes and stuff)\n",
    "# Circuit dropout\n",
    "# Initial connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if device != 'cpu':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CircuitNet(nn.Module):\n",
    "    def __init__(self,circuit_dropout=0.5,circuit_ban_rate = 0.3,num_classes=12):\n",
    "        super(CircuitNet, self).__init__()\n",
    "        \n",
    "        self.circuit_ban_rate = circuit_ban_rate\n",
    "        self.circuit_dropout = circuit_dropout\n",
    "        self.state_size = 100\n",
    "        self.num_lstm_layers = 3\n",
    "        \n",
    "        #monitor use of each circuit to balance training\n",
    "        self.used_circuits = np.zeros([40,2])\n",
    "        for i in range(40):\n",
    "            self.used_circuits[i][0] = i\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.circuits_to_use = 10\n",
    "        self.n_circuits = 20\n",
    "        #self.circuit_in_dim = 25\n",
    "        self.circuit_in_x = 5\n",
    "        self.circuit_in_y = 5\n",
    "        \n",
    "        #circuit picker\n",
    "        self.circuit_picker = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, stride=2),  \n",
    "            nn.Conv2d(16, 8, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.circuit_picker_out = nn.LSTM(8*7*7,(self.n_circuits *  self.circuits_to_use), self.num_lstm_layers)\n",
    "        self.hidden = self.init_hidden()\n",
    "        #self.circuit_picker_out = nn.Linear(8*7*7, (self.n_circuits *  self.circuits_to_use))\n",
    "        \n",
    "        #data pipe\n",
    "        self.data_pipe = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 4, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 4, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, stride=2), \n",
    "            \n",
    "            \n",
    "            nn.Conv2d(32, 16, 4, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 4, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        self.data_pipe_out = nn.Linear(800, (self.circuits_to_use * self.circuit_in_x *  self.circuit_in_y))\n",
    "        \n",
    "            \n",
    "        self.circuits = []\n",
    "        #define circuits\n",
    "        for i in range(self.n_circuits):\n",
    "        \n",
    "            \n",
    "            self.circuits.append(nn.Sequential(\n",
    "                nn.Conv2d(1, 8, kernel_size=2, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                #nn.MaxPool2d(kernel_size=2, stride=2)))\n",
    "            \n",
    "                nn.Conv2d(8, 16, kernel_size=2, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True),\n",
    "                \n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)))\n",
    "        \n",
    "        #connect circuits (this is temporary)\n",
    "        self.connect = nn.Sequential(\n",
    "            nn.Linear(1440, 28*28))\n",
    "        \n",
    "        #final circuit to prediction\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(1440, 400),\n",
    "            nn.Linear(400, 10))\n",
    "        \n",
    "    #init hidden state for lstm layer\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_lstm_layers,1, (self.n_circuits *  self.circuits_to_use), device=device),\n",
    "                torch.zeros(self.num_lstm_layers,1, (self.n_circuits *  self.circuits_to_use), device=device))\n",
    "    \n",
    "    def connection(self,x,verbose):\n",
    "        circuit_pick = self.circuit_picker(x)\n",
    "        circuit_pick = circuit_pick.view(circuit_pick.size(0),1, -1)\n",
    "        \n",
    "        circuit_pick, self.hidden = self.circuit_picker_out(circuit_pick,self.hidden)\n",
    "        \n",
    "        \n",
    "        circuit_pick = circuit_pick.view(circuit_pick.size(0),self.circuits_to_use,self.n_circuits)\n",
    "        circuit_pick = circuit_pick.max(2)[1]\n",
    "        circuit_pick_padded = F.pad(circuit_pick,(0,18)).unsqueeze(1).unsqueeze(1)\n",
    "        circuit_pick_padded = circuit_pick_padded.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        data_pipe_in = torch.cat((circuit_pick_padded,x),2)\n",
    "        data_pipe = self.data_pipe(data_pipe_in)\n",
    "        data_pipe = data_pipe.view(data_pipe.size(0), -1)\n",
    "        data_pipe = self.data_pipe_out(data_pipe)\n",
    "        data_pipe = data_pipe.view(data_pipe.size(0),self.circuits_to_use,self.circuit_in_x, self.circuit_in_y)\n",
    "        bans = np.random.randint(self.n_circuits,size=int(self.circuit_ban_rate*self.n_circuits))\n",
    "        circuit_out = []\n",
    "        for i in range(self.circuits_to_use):\n",
    "            circuit_idx = circuit_pick[:,i]\n",
    "            if(verbose):\n",
    "                print(str(circuit_idx))\n",
    "                \n",
    "            batch = []\n",
    "            for b in range(batch_size):\n",
    "                #print(data_pipe[b][i].shape)\n",
    "                circuit = self.circuits[circuit_idx[b]](data_pipe[b][i].unsqueeze(0).unsqueeze(0))\n",
    "                #apply dropout\n",
    "                if randint(1,100) < self.circuit_dropout*100 or circuit_idx[b] in bans:\n",
    "                    circuit = torch.zeros(circuit.shape,device=device)  \n",
    "                \n",
    "                batch.append(circuit)\n",
    "            batch = torch.cat(batch,0)\n",
    "            circuit_out.append(batch)\n",
    "        circuit_out = torch.cat(circuit_out,1)\n",
    "        return circuit_out\n",
    "    def forward(self, x, verbose):\n",
    "        \n",
    "        circuit_out1 = self.connection(x,verbose)\n",
    "        circuit_out_flat1 = circuit_out1.view(circuit_out1.size(0), -1)\n",
    "        #connect = self.connect(circuit_out_flat1)\n",
    "        #connect = connect.view(connect.size(0),1,28,28)\n",
    "        \n",
    "       # circuit_out2 = self.connection(connect,verbose)\n",
    "        #circuit_out_flat2 = circuit_out2.view(circuit_out2.size(0), -1)\n",
    "        \n",
    "        \n",
    "        out = self.output(circuit_out_flat1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "        \n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "model = CircuitNet(circuit_dropout=0.2, circuit_ban_rate = 0.3).to(device)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data,False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "if device != 'cpu':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "model = CircuitNet().to(device)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    #if device != 'cpu':\n",
    "    #    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    #print(data)\n",
    "    output = model(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 0  Loss : 2.38092  Real : [0 8 3 7]  Pred : [2 2 2 2]\n",
      "Index : 25  Loss : 2.69647  Real : [6 1 9 9]  Pred : [3 0 0 0]\n",
      "Index : 50  Loss : 2.36524  Real : [6 4 7 3]  Pred : [7 7 8 8]\n",
      "Index : 75  Loss : 2.54427  Real : [7 3 2 2]  Pred : [0 9 8 9]\n",
      "Index : 100  Loss : 2.31832  Real : [2 9 2 3]  Pred : [9 3 0 3]\n",
      "Index : 125  Loss : 2.28596  Real : [8 3 2 4]  Pred : [9 9 0 9]\n",
      "Index : 150  Loss : 2.37183  Real : [0 0 8 4]  Pred : [2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "iter_print = 25\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    verbose = False\n",
    "    if(batch_idx % iter_print == 0):\n",
    "        verbose = False\n",
    "    output = model(data,verbose)\n",
    "    loss =  nn.CrossEntropyLoss()(output, target)\n",
    "    #loss = (output-target)**2\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    if(batch_idx % iter_print == 0):\n",
    "        print(\"Index : {}  Loss : {:.5f}  Real : {}  Pred : {}\".format(batch_idx,\n",
    "                                                                       loss[0],target[0:4].cpu().numpy(),\n",
    "                                                                       output[0:4].max(1)[1].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
