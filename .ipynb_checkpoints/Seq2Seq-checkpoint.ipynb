{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'masked_cross_entropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-61b36fbe294f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmasked_cross_entropy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'masked_cross_entropy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequences(length_from, length_to,\n",
    "                     vocab_lower, vocab_upper,\n",
    "                     batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    if length_from > length_to:\n",
    "            raise ValueError('length_from > length_to')\n",
    "\n",
    "    def random_length():\n",
    "        if length_from == length_to:\n",
    "            return length_from\n",
    "        return np.random.randint(length_from, length_to + 1)\n",
    "    \n",
    "    while True:\n",
    " \n",
    "        \n",
    "        padded = np.zeros([batch_size,length_to])\n",
    "        seq_lengths = np.zeros([batch_size])\n",
    "        for i in range(batch_size):\n",
    "            rand = np.random.randint(low=vocab_lower,\n",
    "                              high=vocab_upper,\n",
    "                              size=random_length()).tolist()\n",
    "            seq_lengths[i] = len(rand)\n",
    "            padded[i,0:len(rand)] = rand\n",
    "            \n",
    "       \n",
    "        concat = np.zeros([batch_size,padded.shape[1]+1])\n",
    "        concat[:,0] = seq_lengths\n",
    "        concat[:,1:concat.shape[1]] = padded\n",
    "        \n",
    "        yield concat[:,1:],concat[:,0].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=3, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        self.hidden = None\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths):\n",
    "        input_seqs = input_seqs.unsqueeze(-1).type(torch.FloatTensor)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(input_seqs, input_lengths)\n",
    "        outputs, self.hidden = self.gru(packed, self.hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,output_size,hidden_size,enc_hidden_size,n_layers=3):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(enc_hidden_size, hidden_size, n_layers, bidirectional=True)\n",
    "        self.hidden = None\n",
    "       \n",
    "        self.concat = nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.out = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        rnn_in = encoder_outputs[-1].unsqueeze(0)\n",
    "           \n",
    "        outputs, self.hidden = self.gru(rnn_in, self.hidden)\n",
    "        outputs = self.concat(outputs)\n",
    "        out = self.out(outputs)\n",
    "\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 3\n",
    "batch_size = 25    \n",
    "input_size =1\n",
    "\n",
    "hidden_size = 10\n",
    "enc_model = EncoderRNN(input_size,hidden_size)\n",
    "dec_model = DecoderRNN(input_size,hidden_size,hidden_size)\n",
    "\n",
    "enc_optimizer = torch.optim.Adam(enc_model.parameters(), lr=0.001)\n",
    "dec_optimizer = torch.optim.Adam(dec_model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(10000):\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    d, s = next(random_sequences(max_seq_length, max_seq_length,\n",
    "                     1, 9, \n",
    "                     batch_size))\n",
    "    print(d.shape)\n",
    "    break\n",
    "    enc_out = enc_model(torch.from_numpy(d.T),torch.from_numpy(s))\n",
    "    \n",
    "    all_out = torch.from_numpy(np.zeros([max_seq_length,batch_size,input_size]))\n",
    "    #print(all_out.shape)\n",
    "    for j in range(max_seq_length):\n",
    "\n",
    "        dec_out = dec_model(enc_out)\n",
    "        all_out[j] = dec_out\n",
    "    \n",
    "    d = torch.from_numpy(d).unsqueeze(-1).transpose(0,1)\n",
    "    \n",
    "    loss = torch.nn.L1Loss()(all_out,d)\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    enc_optimizer.step()\n",
    "    dec_optimizer.step()\n",
    "    enc_model.hidden = None\n",
    "    dec_model.hidden = None\n",
    "    #d = d.squeeze(-1).detach().numpy().T[0]\n",
    "    #all_out = all_out.squeeze(-1).detach().numpy().T[0]\n",
    "    \n",
    "    d = d[:,0].squeeze(-1).detach().numpy()\n",
    "    \n",
    "    all_out = all_out[:,0].squeeze(-1).detach().numpy()\n",
    "    if i % 100 == 0:\n",
    "        print(\"Loss : {}  Real : {}  Pred : {}\".format(loss.detach().numpy(),d,all_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
